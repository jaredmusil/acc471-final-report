[
["index.html", "Analysis of the “automobile-loss-prediction” dataset Chapter 1 Introduction", " Analysis of the “automobile-loss-prediction” dataset Illinois State University - ACC 471 - Final Report Jared Musil &amp; Jake McNair 2017-12-13 Chapter 1 Introduction Travis CI test The ability to utilize analytics to predict automobeile lossess is a area of active research and application throughout the insurance and fin-tech industries. All of the “big four” US domiciled auto insurrers being State Farm, Geico, Allstate, and Progressive are actively engaging in research to operationalize analytical models to increase operational efficency. This dataset is representitive of claims data common to all of these auto insurance providers, and the industry at large. From a consumer standpoint, this has the potential to reduce average claim times, reduce premium costs, and improve claims decisions (total loss, not total loss). This report is differes only to those being done by those auto insurers by its dataset alone, and can be seen as an analysis that we would provide to a manager at one of those companies. Throughout this report, the columns of our dataset will be refered to as factors, and the rows of our dataset will be refered to as reccords. This is because it follows the terminology used by the R statistical programming language, which was the analytical tool used in this report. This was chosen to allow for reproducable research and full transparency of the methods used to arrive at our conclusions. The code itself has been omitted from the report for brevity, but is available for review and reuse at the following URL: https://github.com/jaredmusil/acc471-final-report "],
["problem-description.html", "Chapter 2 Problem Description", " Chapter 2 Problem Description This data set consists of three types of entities: (a) the specification of an auto in terms of various characteristics, (b) its assigned insurance risk rating, (c) its normalized losses in use as compared to other cars. The second rating corresponds to the degree to which the auto is more risky than its price indicates. Cars are initially assigned a risk factor symbol associated with its price. Then, if it is more risky (or less), this symbol is adjusted by moving it up (or down) the scale. Actuarians call this process “symboling”. A value of +3 indicates that the auto is risky, -3 that it is probably pretty safe. The third factor is the relative average loss payment per insured vehicle year. This value is normalized for all autos within a particular size classification (two-door small, station wagons, sports/speciality, etc…), and represents the average loss per car per year. "],
["data.html", "Chapter 3 Data", " Chapter 3 Data Before doing any analysis, the factors within the dataset were first checked for missing or invalid data. The individual factors can be described as follows: 15 continuous, 10 nominal, and 1 integer. Seven of the factors contained missing or improperly coded data. In this dataset in partular, all missing data has been coded with the value of ?. In all cases below, the records containing the missing data have been removed. N Factor Number of records missing a value 2 normalized-losses 41 6 num-of-doors 2 19 bore 4 20 stroke 4 22 horsepower 2 23 peak-rpm 2 26 price 4 Of the original 205 records, 46 were removed because they contained missing data in one or more of the above listed factors, which in this case was uniformly coded as a ?. This resulted in a dataset of 159 records of clean data. No other factors needed cleaning up, as the data was properly coded for each record. Table 3.1: Data Dictionary N Description Values 1 symboling -3, -2, -1, 0, 1, 2, 3 2 normalized-losses continuous from [65 to 256] 3 make alfa-romero, audi, bmw, chevrolet, dodge, honda, isuzu, jaguar, mazda, mercedes-benz, mercury, mitsubishi, nissan, peugot, plymouth, porsche, mitsubishi, nissan, peugot, plymouth, porsche, renault, saab, subaru, toyota, volkswagen, volvo  4 fuel-type diesel, gas 5 aspiration std, turbo 6 num-of-doors four, two 7 body-style hardtop, wagon, sedan, hatchback, convertible 8 drive-wheels 4wd, fwd, rwd.  9 engine-location front, rear 10 wheel-base continuous from [86.6 to 120.9] 11 length continuous from [141.1 to 208.1] 12 width continuous from [60.3 to 72.3] 13 height continuous from [47.8 to 59.8] 14 curb-weight: continuous from [1488 to 4066] 15 engine-type dohc, dohcv, l, ohc, ohcf, ohcv, rotor 16 num-of-cylinders eight, five, four, six, three, twelve, two 17 engine-size continuous from [61 to 326] 18 fuel-system 1bbl, 2bbl, 4bbl, idi, mfi, mpfi, spdi, spfi 19 bore continuous from [2.54 to 3.94] 20 stroke continuous from [2.07 to 4.17] 21 compression-ratio continuous from [7 to 23] 22 horsepower continuous from [48 to 288] 23 peak-rpm continuous from [4,150 to 6,600] 24 city-mpg continuous from [13 to 49] 25 highway-mpg continuous from [16 to 54] 26 price continuous from [5,118 to 45,400] Of the remaining data, the reccords were split into two equal groups named training, and test where each held 50% of the reccords in the dataset. The objective factor in the dataset is determined to be symboling. For the remainder of the factors, the summary statistics were examined for continuous variables (Minimum, 1st Quartile, Median 3rd Quartile, and Maximum). For discrete factors we simply looked at the raw counts of each. A few cars had unique values sjch as the lone three cylinder hatchback from chevrolet, and the lone mixed fuel injection (mfi) dodge hatchback. They do not at first analysis seem to be outliers but were re-evaluated after looking at if they skewed our resulting models. A rough summary of the factors summary statistics is as follows: ## symboling normalized_losses make fuel_type aspiration ## Min. :-2.0000 Min. : 65.0 toyota :31 diesel: 15 std :132 ## 1st Qu.: 0.0000 1st Qu.: 94.0 nissan :18 gas :144 turbo: 27 ## Median : 1.0000 Median :113.0 honda :13 ## Mean : 0.7358 Mean :121.1 subaru :12 ## 3rd Qu.: 2.0000 3rd Qu.:148.0 mazda :11 ## Max. : 3.0000 Max. :256.0 volvo :11 ## (Other):63 ## num_of_doors body_style drive_wheels engine_location ## four:95 convertible: 2 4wd: 8 front:159 ## two :64 hardtop : 5 fwd:105 ## hatchback :56 rwd: 46 ## sedan :79 ## wagon :17 ## ## ## wheel_base length width height ## Min. : 86.60 Min. :141.1 Min. :60.30 Min. :49.40 ## 1st Qu.: 94.50 1st Qu.:165.7 1st Qu.:64.00 1st Qu.:52.25 ## Median : 96.90 Median :172.4 Median :65.40 Median :54.10 ## Mean : 98.26 Mean :172.4 Mean :65.61 Mean :53.90 ## 3rd Qu.:100.80 3rd Qu.:177.8 3rd Qu.:66.50 3rd Qu.:55.50 ## Max. :115.60 Max. :202.6 Max. :71.70 Max. :59.80 ## ## curb_weight engine_type num_of_cylinders engine_size fuel_system ## Min. :1488 dohc: 8 eight: 1 Min. : 61.0 1bbl:11 ## 1st Qu.:2066 l : 8 five : 7 1st Qu.: 97.0 2bbl:63 ## Median :2340 ohc :123 four :136 Median :110.0 idi :15 ## Mean :2461 ohcf: 12 six : 14 Mean :119.2 mfi : 1 ## 3rd Qu.:2810 ohcv: 8 three: 1 3rd Qu.:135.0 mpfi:64 ## Max. :4066 Max. :258.0 spdi: 5 ## ## bore stroke compression_ratio horsepower ## Min. :2.54 Min. :2.070 Min. : 7.00 Min. : 48.00 ## 1st Qu.:3.05 1st Qu.:3.105 1st Qu.: 8.70 1st Qu.: 69.00 ## Median :3.27 Median :3.270 Median : 9.00 Median : 88.00 ## Mean :3.30 Mean :3.236 Mean :10.16 Mean : 95.84 ## 3rd Qu.:3.56 3rd Qu.:3.410 3rd Qu.: 9.40 3rd Qu.:114.00 ## Max. :3.94 Max. :4.170 Max. :23.00 Max. :200.00 ## ## peak_rpm city_mpg highway_mpg price ## Min. :4150 Min. :15.00 Min. :18.00 Min. : 5118 ## 1st Qu.:4800 1st Qu.:23.00 1st Qu.:28.00 1st Qu.: 7372 ## Median :5200 Median :26.00 Median :32.00 Median : 9233 ## Mean :5114 Mean :26.52 Mean :32.08 Mean :11446 ## 3rd Qu.:5500 3rd Qu.:31.00 3rd Qu.:37.00 3rd Qu.:14720 ## Max. :6600 Max. :49.00 Max. :54.00 Max. :35056 ## "],
["methods-used.html", "Chapter 4 Methods Used", " Chapter 4 Methods Used A number of analytical methods are available for use such as decision trees, classification trees, linear-regression. Not all of these techniques makes sense for our purpouses as they are used to predict diffrent types of information. The main goal of our analysis is to predict how risky a particular car is using the symboling scale: [-3, -2, -1, 0, +1, +2, +3]. Since this output variable has class levels, and is not continuous, the appropriate analysis method is a classification tree. Note that if we to not be using the symboling scale, then a regression tree would be appropriate as it would have output a continuous risk variable. The below chart graphically summarizes this nicely. Source: http://www.simafore.com/blog/bid/62482/2-main-differences-between-classification-and-regression-trees "],
["results.html", "Chapter 5 Results 5.1 Random Forest 5.2 Linear Regression 5.3 Regression Tree 5.4 Classification Tree", " Chapter 5 Results … 5.1 Random Forest First we decided to use a random forest models to get a rough approximation of what input factors were important. Note that this type of analysis tends to favor factors with high numbers of levels. We did not try and correct for this as it is more of a starting point in understanding our dataset for use in the below models. As can be seen from the plot, make, num_of_doors, and wheel_base all showed high relative importance to the symboling classification factor. The relative drop off in relative importance prompted us to limit our inquiry into just these three predictors for the next model. 5.2 Linear Regression Armed with the relative factor importance, we first tried a few variations of simple linear regression models with factors that we thought would be important, such as: make alone. num_of_doors alone. make and num_of_doors. make, numofdoors, and wheelbase. all variables included ## ## Call: ## lm(formula = symboling ~ make, data = training_data) ## ## Residuals: ## Min 1Q Median 3Q Max ## -2.000 -0.500 0.000 0.500 2.667 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 2.0000 0.9156 2.184 0.03260 * ## makedodge -1.0000 1.1214 -0.892 0.37585 ## makehonda -1.5714 0.9788 -1.605 0.11331 ## makemazda -1.5000 0.9889 -1.517 0.13425 ## makemercedes-benz -1.6667 1.0572 -1.576 0.11985 ## makemitsubishi -1.0000 1.0030 -0.997 0.32250 ## makenissan -1.1818 0.9563 -1.236 0.22104 ## makepeugot -2.0000 1.1214 -1.784 0.07924 . ## makeplymouth -1.0000 1.1214 -0.892 0.37585 ## makeporsche 1.0000 1.2948 0.772 0.44278 ## makesaab 0.5000 1.0237 0.488 0.62690 ## makesubaru -1.2500 0.9711 -1.287 0.20267 ## maketoyota -1.5000 0.9438 -1.589 0.11690 ## makevolkswagen 0.2000 1.0030 0.199 0.84258 ## makevolvo -3.1667 0.9889 -3.202 0.00213 ** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 0.9156 on 64 degrees of freedom ## Multiple R-squared: 0.5097, Adjusted R-squared: 0.4024 ## F-statistic: 4.752 on 14 and 64 DF, p-value: 7.252e-06 ## [1] &quot;RMSE: &quot; ## ## Call: ## lm(formula = symboling ~ num_of_doors, data = training_data) ## ## Residuals: ## Min 1Q Median 3Q Max ## -2.1064 -0.6562 -0.1064 0.3438 1.8936 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 0.1064 0.1327 0.802 0.425 ## num_of_doorstwo 1.5499 0.2084 7.436 1.23e-10 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 0.9095 on 77 degrees of freedom ## Multiple R-squared: 0.4179, Adjusted R-squared: 0.4104 ## F-statistic: 55.29 on 1 and 77 DF, p-value: 1.231e-10 ## [1] &quot;RMSE: &quot; ## ## Call: ## lm(formula = symboling ~ make + num_of_doors, data = training_data) ## ## Residuals: ## Min 1Q Median 3Q Max ## -1.1757 -0.2767 0.0000 0.3496 1.7508 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 0.6261 0.6280 0.997 0.3225 ## makedodge -0.3131 0.7500 -0.417 0.6778 ## makehonda -0.9826 0.6546 -1.501 0.1383 ## makemazda -0.5841 0.6658 -0.877 0.3837 ## makemercedes-benz -0.7508 0.7108 -1.056 0.2949 ## makemitsubishi -0.4505 0.6702 -0.672 0.5039 ## makenissan -0.3075 0.6437 -0.478 0.6345 ## makepeugot -0.6261 0.7615 -0.822 0.4141 ## makeplymouth 0.3739 0.7615 0.491 0.6252 ## makeporsche 1.0000 0.8616 1.161 0.2502 ## makesaab 1.1869 0.6854 1.732 0.0882 . ## makesubaru -0.3913 0.6532 -0.599 0.5512 ## maketoyota -0.8131 0.6326 -1.285 0.2034 ## makevolkswagen 1.0243 0.6736 1.521 0.1334 ## makevolvo -1.7928 0.6754 -2.654 0.0100 * ## num_of_doorstwo 1.3739 0.1521 9.030 5.75e-13 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 0.6093 on 63 degrees of freedom ## Multiple R-squared: 0.7863, Adjusted R-squared: 0.7354 ## F-statistic: 15.45 on 15 and 63 DF, p-value: 1.037e-15 ## [1] &quot;RMSE: &quot; ## ## Call: ## lm(formula = symboling ~ make + num_of_doors + wheel_base, data = training_data) ## ## Residuals: ## Min 1Q Median 3Q Max ## -1.14833 -0.21848 -0.00841 0.27748 1.15678 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 13.54499 2.45785 5.511 7.33e-07 *** ## makedodge 0.26155 0.63337 0.413 0.681067 ## makehonda -0.15515 0.56613 -0.274 0.784960 ## makemazda 0.38575 0.58280 0.662 0.510495 ## makemercedes-benz 1.44589 0.71886 2.011 0.048639 * ## makemitsubishi 0.28776 0.57445 0.501 0.618191 ## makenissan 0.61498 0.56253 1.093 0.278517 ## makepeugot 1.79491 0.77739 2.309 0.024297 * ## makeplymouth 0.76996 0.63812 1.207 0.232166 ## makeporsche 1.86682 0.73504 2.540 0.013614 * ## makesaab 2.52890 0.62265 4.062 0.000139 *** ## makesubaru 0.42819 0.56460 0.758 0.451095 ## maketoyota 0.26424 0.56334 0.469 0.640676 ## makevolkswagen 1.99522 0.58902 3.387 0.001230 ** ## makevolvo 0.33694 0.68761 0.490 0.625856 ## num_of_doorstwo 1.01682 0.14298 7.112 1.38e-09 *** ## wheel_base -0.14210 0.02642 -5.379 1.21e-06 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 0.5071 on 62 degrees of freedom ## Multiple R-squared: 0.8543, Adjusted R-squared: 0.8167 ## F-statistic: 22.72 on 16 and 62 DF, p-value: &lt; 2.2e-16 ## [1] &quot;RMSE: &quot; 5.3 Regression Tree … Lift Chart … Decile Chart … 5.4 Classification Tree Lift Chart … Decile Chart … "],
["recomentations.html", "Chapter 6 Recomentations", " Chapter 6 Recomentations … "],
["future-analysis.html", "Chapter 7 Future Analysis", " Chapter 7 Future Analysis As with any data analysis, the quality of the input data will determine the quality of the resulting models. In this case we started with 26 factors. A good way to increase the quality of the model would be to provide it with more factors and potentially more levels within the factors. All of this data also is only related to the automobeile itself, and does not account for the individual driving it. While some behavorial and demographic factors protected by federal law from being used for analysis like race and religion(CITE), Others such as gender are allowed. Including these behavorial factors as inputs into the model would be an opportunity to strethen the existing model. Technology and in partucular the increase of telematics within vehicles and internet of things (IoT) connected devices, will increase the ubiquity and variety of this datastream. With the advances in autonomous vehicles, behavorial factors may impact results less, but is something to monitor for the future of auto risk classification. "],
["conculsion.html", "Chapter 8 Conculsion", " Chapter 8 Conculsion Given the results of this analysis, we "],
["references.html", "References", " References "]
]
